{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install bs4\n",
    "!pip install pandas\n",
    "!pip install torch\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-base\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5f7cd5cae3b8938a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "url='https://www.nice.org.uk/guidance/published?ndt=Guidance&ngt=Technology%20appraisal%20guidance&ps=9999'\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "    'Accept-Language': 'en-US,en;q=0.5',\n",
    "    'DNT': '1',  # Do Not Track Request Header\n",
    "    'Connection': 'keep-alive'\n",
    "}\n",
    "\n",
    "# Make the GET request with the specified headers\n",
    "response = requests.get(url, headers=headers)\n",
    "html_content = response.text\n",
    "\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "rows = soup.find_all('tr')\n",
    "\n",
    "with open('evidence_NICE_lists.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    # Write the CSV header\n",
    "    csvwriter.writerow(['Title', 'Link', 'TA Number', 'Publication Date', 'Last Reviewed'])\n",
    "\n",
    "    # Iterate over each row in the table\n",
    "    for row in rows:\n",
    "        # Extract data from columns\n",
    "        cols = row.find_all('td')\n",
    "        if cols:\n",
    "            a_tag = cols[0].find('a')\n",
    "            title = a_tag.text.strip() if a_tag else ''\n",
    "            link = a_tag['href'] if a_tag else ''\n",
    "            ta_number = cols[1].text.strip()\n",
    "            publication_date = cols[2].text.strip()\n",
    "            last_reviewed = cols[3].text.strip()\n",
    "\n",
    "            # Write the row data to the CSV file\n",
    "            csvwriter.writerow([title, link, ta_number, publication_date, last_reviewed])\n",
    "\n",
    "print(\"CSV file with links has been created successfully.\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "105281aa45f2e405"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "def get_url_data(extension):\n",
    "    url = f'''https://www.nice.org.uk{extension}'''\n",
    "\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3',\n",
    "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "        'Accept-Language': 'en-US,en;q=0.5',\n",
    "        'DNT': '1',  # Do Not Track Request Header\n",
    "        'Connection': 'keep-alive'\n",
    "    }\n",
    "\n",
    "\n",
    "    # Make the GET request with the specified headers\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code==200:\n",
    "\n",
    "        html_content = response.text\n",
    "        return html_content\n",
    "    else:\n",
    "        return None\n",
    "def get_guidance_menu_links(soup):\n",
    "    guidance_menu = soup.find('nav', class_='stacked-nav')\n",
    "    final_links=[]\n",
    "    if guidance_menu:\n",
    "        links = guidance_menu.find_all('a')\n",
    "        for link in links[1:]:\n",
    "            final_links.append([link.get_text(strip=True),link.get('href')])\n",
    "        return final_links\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def classify_nice_guidance(text):\n",
    "    # Categories based on key phrases\n",
    "    if 'cancer drugs fund' in text.lower():\n",
    "        CDF = True\n",
    "    else:\n",
    "        CDF = False\n",
    "    if \"is not recommended\" in text:\n",
    "        return \"Not Recommended\", CDF\n",
    "    # elif \"recommended as an option for treating\" in text and \"Cancer Drugs Fund\" in text:\n",
    "    #     return \"Recommended-CDF\"\n",
    "    elif \"recommended as an option for\" in text and \"only if\" in text:\n",
    "        return \"Optimised\",CDF\n",
    "    # elif \"recommended for use\" and \"Cancer Drugs Fund\" in text:\n",
    "    #     return \"Optimised-CDF\"\n",
    "    elif \"recommended, within its marketing authorisation\" in text or \"recommended\" in text:\n",
    "        return \"Recommended\",CDF\n",
    "    else:\n",
    "        return \"Uncategorized\",CDF\n",
    "\n",
    "def get_llm_output(prompt):\n",
    "    tur_inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    tur_outputs = model.generate(tur_inputs, max_new_tokens=128)\n",
    "    return tokenizer.decode(tur_outputs[0],skip_special_tokens = True)\n",
    "\n",
    "def LLM_questions(question_type,MEDICAL_DOCUMENT):\n",
    "    if question_type=='outcome_tech':\n",
    "      prompt=f\"Context:{MEDICAL_DOCUMENT} \\n Question: Which tecnology is recommended? answer: \"\n",
    "      gen_output=get_llm_output(prompt)\n",
    "\n",
    "    elif question_type=='outcome_dis':\n",
    "      prompt=f\"Context:{MEDICAL_DOCUMENT} \\n Question: For treating which condition? answer: \"\n",
    "      gen_output=get_llm_output(prompt)\n",
    "\n",
    "    elif question_type=='outcome_text':\n",
    "      prompt=f\"Context:{MEDICAL_DOCUMENT} \\n Question: What are the constraints? answer:  \"\n",
    "      gen_output=get_llm_output(prompt)\n",
    "\n",
    "    elif question_type=='reason_text':\n",
    "      prompt=f\"Context:{MEDICAL_DOCUMENT} \\n Question: what are the reasons? answer: \"\n",
    "      gen_output=get_llm_output(prompt)\n",
    "    elif question_type=='initial_auth':\n",
    "      prompt=f\"Context:{MEDICAL_DOCUMENT} \\n Question: For which condition it was initial authorized? answer: \"\n",
    "      gen_output=get_llm_output(prompt)\n",
    "    elif question_type=='initial_condition':\n",
    "      prompt=f\"Context:{MEDICAL_DOCUMENT} \\n Question: Under what conditions is the treatment initially authorized? answer: \"\n",
    "      gen_output=get_llm_output(prompt)\n",
    "    elif question_type=='price_text':\n",
    "      prompt=f\"Context:{MEDICAL_DOCUMENT} \\n Question: what is the price for treatment? answer: \"\n",
    "      gen_output=get_llm_output(prompt)\n",
    "\n",
    "    return gen_output\n",
    "\n",
    "def get_recommendation_reason(div_soup):\n",
    "    reason_text=''\n",
    "    recommendation_text = ''\n",
    "    recommendation_cat=''\n",
    "    CDF=False\n",
    "    treatment,condition,constraints,reasons_llm='','','',''\n",
    "    if div_soup.find('div'):\n",
    "        recommendation_text=div_soup.find('div').get_text(strip=True)\n",
    "        treatment=LLM_questions('outcome_tech',recommendation_text)\n",
    "        condition=LLM_questions('outcome_dis',recommendation_text)\n",
    "        constraints=LLM_questions('outcome_text',recommendation_text)\n",
    "        recommendation_cat,CDF=classify_nice_guidance(recommendation_text)\n",
    "        strong_tag = div_soup.find('strong', string=\"Why the committee made these recommendations\")\n",
    "        if strong_tag:\n",
    "            for next_p in strong_tag.find_all_next('p'):\n",
    "                reason_text += next_p.get_text(strip=True) + \" \"\n",
    "\n",
    "        if len(reason_text)>1:\n",
    "          reasons_llm=LLM_questions('reason_text',reason_text)\n",
    "        return recommendation_text,recommendation_cat,CDF,reason_text,treatment,condition,constraints,reasons_llm\n",
    "    else:\n",
    "        return recommendation_text,recommendation_cat,CDF,reason_text,treatment,condition,constraints,reasons_llm\n",
    "\n",
    "def extract_size(size_str):\n",
    "    # Extract the numerical value from the size string\n",
    "    match = re.search(r'(\\d+(\\.\\d+)?)\\s*(MB|KB)', size_str, re.I)\n",
    "    if match:\n",
    "        size = float(match.group(1))\n",
    "        unit = match.group(3).upper()\n",
    "        if unit == 'KB':\n",
    "            size = size / 1024  # Convert KB to MB\n",
    "        return size\n",
    "    return 0\n",
    "\n",
    "\n",
    "def get_eol_sm(url):\n",
    "    response = requests.get(url)\n",
    "    end_of_life = False\n",
    "    severity = False\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text,'html.parser')\n",
    "        soup_text= soup.get_text()\n",
    "        if 'end of life' in soup_text.lower():\n",
    "            end_of_life=True\n",
    "        if 'severity' in soup_text.lower():\n",
    "            severity=True\n",
    "    return end_of_life,severity\n",
    "\n",
    "def get_information_medicine(div_soup):\n",
    "    authorisation=''\n",
    "    auth_condition=''\n",
    "    auth_treatment=''\n",
    "    price_value=''\n",
    "    dosage=''\n",
    "    price=''\n",
    "    if div_soup.find('div',title='Marketing authorisation indication'):\n",
    "        authorisation=div_soup.find('div',title='Marketing authorisation indication').find('p').get_text(strip=True)\n",
    "        auth_treatment=LLM_questions('initial_auth',authorisation)\n",
    "        auth_condition=LLM_questions('initial_condition',authorisation)\n",
    "    if div_soup.find('div',title='Dosage in the marketing authorisation'):\n",
    "        dosage=div_soup.find('div',title='Dosage in the marketing authorisation').find('p').get_text(strip=True)\n",
    "    if div_soup.find('div',title='Price'):\n",
    "        price=div_soup.find('div',title='Price').find('p').get_text(strip=True)\n",
    "        price_value=LLM_questions('price_text',price)\n",
    "    return authorisation,dosage,price,auth_condition,auth_treatment,price_value\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "432d5b10dea8544"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "TAR=pd.read_csv('evidence_NICE_lists.csv',sep=',')\n",
    "\n",
    "TAR['Publication Date'] = pd.to_datetime(TAR['Publication Date'])\n",
    "\n",
    "TAR = TAR[TAR['Publication Date'] >= '2018-01-01']\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f66d9b100fff6d89"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "TAR.head(5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f26af28530dc98"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "final_csv=[]\n",
    "\n",
    "for row in TAR.iterrows():\n",
    "    title=row[1]['Title']\n",
    "    TAnumber=row[1]['TA Number']\n",
    "    print(TAnumber)\n",
    "    extension=f'''/{\"/\".join(row[1]['Link'].split(\"/\")[-2:])}'''\n",
    "    recommendation, reason = 'Not Recommended',''\n",
    "    authorization, dosage, price= '','',''\n",
    "    html_content=get_url_data(extension)\n",
    "    recommendation_cat= 'Not Recommended'\n",
    "    CDF=False\n",
    "    end_of_life = False\n",
    "    severity_modifiers = False\n",
    "    Technology,condition,constraints,reasons_llm='','','',''\n",
    "    auth_condition,auth_treatment,price_value='','',''\n",
    "\n",
    "    # Parse the HTML content\n",
    "    if html_content:\n",
    "      soup = BeautifulSoup(html_content, 'html.parser')\n",
    "      guidance_menus=get_guidance_menu_links(soup)\n",
    "\n",
    "      url=f'''{row[1]['Link']}/chapter/3-Committee-discussion'''\n",
    "      end_of_life,severity_modifiers=get_eol_sm(url)\n",
    "\n",
    "      for guidance_menu_lists in guidance_menus[:2]:\n",
    "          guidance_menu_list=guidance_menu_lists[1]\n",
    "          make_id=f'''{guidance_menu_list.split(\"/\")[2]}-{guidance_menu_list.split(\"/\")[4].lower()}'''\n",
    "          soup = BeautifulSoup(get_url_data(guidance_menu_list),'html.parser')\n",
    "          if soup.find('div',id=make_id):\n",
    "              div_soup = soup.find('div', id=make_id)\n",
    "          else:\n",
    "              div_soup = soup.find('div', title=guidance_menu_lists[0])\n",
    "          # Find the recommendation and reason sections\n",
    "          if \"recommendation\" in make_id:\n",
    "              recommendation,recommendation_cat,CDF,reason,Technology,condition,constraints,reasons_llm=get_recommendation_reason(div_soup)\n",
    "          if 'information-about' in make_id:\n",
    "              authorization,dosage,price,auth_condition,auth_treatment,price_value=get_information_medicine(div_soup)\n",
    "\n",
    "      final_csv.append([TAnumber,title,recommendation,Technology,condition,constraints,recommendation_cat,CDF,reason,reasons_llm,authorization,auth_condition, \n",
    "                        auth_treatment,dosage,price,price_value,\n",
    "                        end_of_life,severity_modifiers])\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d3645b2b7ec8039"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dd=pd.DataFrame(final_csv)\n",
    "dd.columns=['TA_Number','Indication','Outcome','Technology','Condition','Constraints','Category','CDF','Reasons','Reason_LLM','Initial Authorization'\n",
    "                                                       ,'Authorization_Condition','Authorization_Treatment','Dosage','Price','Price_Value','EoL','Severity Modifiers']\n",
    "\n",
    "dd.to_csv('Recommendations_NICE_papers.tsv',sep=';',index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "964ae5764a6d1a51"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
